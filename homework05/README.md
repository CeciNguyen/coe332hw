# Undone (The Sweater Container) - Homework 05 - Analyzing the ISS Data with Smarter Software  

## What to Expect?
Within the folder, you will find a python script named "iss_tracker.py". 
This file contains different app routes thatwill help the user obtain and manipulate 
parts of the data. The second file you will find is an assembled docker file named
"Dockerfile" that contains commands for building a new image for iss-tracker.py. 

## The ISS Data Set
What is the ISS and what is the data set? The ISS is NASA's International Space 
Station! The data set provided by the Trajectory Operations and Planning Officer 
shows where the ISS is located at different times. So cool right? 

So, how exactly are you supposed to access the data set? Great question! 
You would need to open up a browser and visit this link: 
**[ISS Data Set](https://spotthestation.nasa.gov/trajectory_data.cfm)**

From there, you will see that you have the option to download the data set as a TXT 
file or an XML file. For the purposes of this python script, you would need to 
download the XML file. The data set provides position and velocity data generated by 
the ISS Trajectory Operations and Planning Officer flight controllers at NASA!

## Try it out!
Now there are a couple of ways that you can interface with the code. 
First is through pulling from the repository directly and using the flask app in the command line. The second is using a docker image container with preset code.

### The Flask App and How to Use it

**What is it?**
The flask application is written in the python script "iss_tracker.py". It is mainly used for querying the ISS position and velocity data through various app routes!

**How Do You Access it?**
In order to actually run the application:

1. Log into your vm in two seperate command line windows using:
``username-vm``
2. Pull the data from the repository 
3. Then in one of the windows run the debugger server using:
``flask --app app --debug run``
4. Once the server is running, you can then start inputting the different queries in the other window you logged into
5. To run the queries, you must use the command:
``curl localhost:5000``

### The Docker Image and How to Use it

**What is it?**
Docker is a containerization platform that can package software called containers for
others to use! The Dockerfile included in the repository helps to build the docker
image that was used for iss_tracker.py.

**How Do You Access it?**
In order to obtain the container and run the docker image, there are two ways!

If you would like to just obtain the Docker Image and run the code:
1. pull the docker image in your vm with the handle:
``docker pull dcn558/iss_tracker:hw05`` 
2. run the image in seperate vm window with the command: 
``docker run -it --rm -p 5000:5000 dcn558/iss_tracker:hw05``
3. run the different routes

If you would like to start from the Dockerfile and build your own image:
1. clone the repository to obtain the Dockerfile and the python script in one vm
window
2. create your own docker hub account
3. once you modify the code or make your own code, you can build your own image
using:
``docker build -t <dockerhubusername>/iss_tracker:<version> .`` 
4. then to check if you have created your image run the line: ``docker images``
5. then to test your image, open another vm window and type the command:
``docker run -it --rm -p 5000:5000 username/iss_tracker:<version>``
6. now you can interface with the container and the code in the other vm window!  

### What are the Different Queries?
In this python script, there are eight different routes you can experiment with.

1. If you want to retrieve the whole entire data set, you can input:

``curl localhost:5000/``

This will return the whole entire data set as a dictionary. So if you see your screen flash with a bunch of numbers, 
do not be alarmed! That is just the computer communicating that it was able to turn the XML file into a readable 
dictionary for you to manipulate.

2. If you want to see all of the Epochs in the data set, you can input:

``curl localhost:5000/epochs``

This will return all of the Epochs ***ONLY***. You will multiple lines that look like:

> 2023-048T12:04:00.000Z

3. Now, what if you want to see a set of Epochs starting from the middle of the data set? You can now add a query parameter: limit and offset!
So if you would like to see the Epochs 10 through 14, you would input:

``curl localhost:5000/epochs?limit=4&offset=9``

Since the computer starts printing from index 0, you would want your offset to equal the Epoch that you want - 1 (ex: 6th Epoch = offset of 5).
You will most likely see a list that looks like this:

> [ 
>
>  "2023-082T11:48:00.000Z",
>
>  "2023-082T11:52:00.000Z",
>
>  "2023-082T11:56:00.000Z",
>
>  "2023-082T12:00:00.000Z"
>
> ]

4. If you want to see the state vectors for a specific Epoch, you can input:

``curl localhost:5000/epochs/(an integer)``

So, if you wanted to see the second Epoch data set, you would want to put:

``curl localhost:5000/epochs/2``

This will return the data set that belongs to the specific Epoch! You will see something along the lines of:

> X = -5998.4652356788401
>
> Y= 391.26194859011099
>
> Z = -3164.26047476557
>
> X_DOT = -2.8799691318087701
>
> Y_DOT = -5.2020406581448801
>
> Z_DOT = 4.8323394499086101

5. If you want to see the speed for a specific Epoch in the data set, you can input:

``curl localhost:5000/epochs/(an integer)/speed``

So if you wanted to see the second Epoch's speed, you would type:

``curl localhost:5000/epochs/2/speed``

This will return a float! 

6. If you need a friendly reminder of what each app route does, you are in luck! In order to see each app route and their function, just input:

``curl localhost:5000/help``

This will return a list of app routes provided in the file and their descriptions.

7. Let's say that you notice that the data set you are using is outdated, well no problem! You can delete the current data that you have stored using:

``curl localhost:5000/delete-data -X DELETE``

It is important to note that you must need the: `` -X DELETE`` because the action for the app route is not 'GET' like the previous routes. So if you forget that part of the command, it will return an error. 

To test if you cleared the data, you can try to run:

``curl localhost:5000/``

and it should return an empty data set.

> []

8. In order to get updated data, you should input: 

``curl localhost:5000/post-data -X POST`` 

This should return an updated data set as a dictionary!

After you delete your data, you need to reload the data using post in order to run the other routes! And just like with the "delete-data" route, you need to make sure to have the ``-X POST`` in the command for the route to do its action.






